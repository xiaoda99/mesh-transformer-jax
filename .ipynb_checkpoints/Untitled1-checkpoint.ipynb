{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e47d0c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'  #'last', 'last_expr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f38c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'text': [[1, 2, 3], [2, 4]], 'label': [0, 1]}\n",
    "ds = Dataset.from_dict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6355e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"rotten_tomatoes\"\n",
    "dataset = load_dataset(dataset_name, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a1cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf316e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b2e33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, example in enumerate(dataset):\n",
    "    if i == 3: break\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7b383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = '/nas/xd/.cache/torch/transformers/'\n",
    "model_name = 'EleutherAI/gpt-j-6B'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name, cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ef5f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer('Good morning!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ac427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize_function(examples): return tokenizer(example['text'])\n",
    "tokenized_dataset = dataset.map(lambda example: tokenizer(example['text']),\n",
    "    batched=True, num_proc=None, remove_columns=dataset.column_names)  # run_clm_flax.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66ccbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e963e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.remove_columns('attention_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be3ba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa902afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, example in enumerate(tokenized_dataset):\n",
    "    if i == 3: break\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cef39a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mesh-transformer-jax, https://www.tensorflow.org/tutorials/load_data/tfrecord\n",
    "def _int64_feature(value): return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def write_tfrecords(dataset, fp):\n",
    "    with tf.io.TFRecordWriter(fp) as writer:\n",
    "        for example in dataset:\n",
    "            feature = {\"input_ids\": _int64_feature(example['input_ids'])}\n",
    "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "            writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b48f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = f'{dataset_name}_train_{len(tokenized_dataset)}.tfrecords'\n",
    "write_tfrecords(tokenized_dataset, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6b4f9a",
   "metadata": {},
   "source": [
    "## load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e26969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(example_proto): # https://zhuanlan.zhihu.com/p/552951305\n",
    "    feature_desc = {\"input_ids\": tf.io.VarLenFeature(tf.int64)}\n",
    "    example = tf.io.parse_single_example(example_proto, feature_desc)\n",
    "    for name in list(example.keys()):\n",
    "        t = example[name]\n",
    "        if t.dtype == tf.int64: t = tf.cast(t, dtype=tf.int32)\n",
    "        example[name] = tf.sparse.to_dense(t, default_value=0)\n",
    "        # example[name] = tf.sparse.to_dense(tf.sparse.reorder(t)) # mesh-transformer-jax\n",
    "    return example\n",
    "\n",
    "def shard(data, batch_size=None):\n",
    "    return jax.tree_map(lambda x: x.numpy().reshape(batch_size + x.shape[1:]), data)  # mtj\n",
    "    \n",
    "def prefetch(dataset, n_prefetch=None):\n",
    "    # Taken from: https://github.com/google-research/vision_transformer/blob/master/vit_jax/input_pipeline.py\n",
    "    ds_iter = iter(dataset)\n",
    "    ds_iter = map(lambda x: jax.tree_map(lambda t: np.asarray(memoryview(t)), x), ds_iter)\n",
    "    if n_prefetch: ds_iter = flax.jax_utils.prefetch_to_device(ds_iter, n_prefetch)\n",
    "    return ds_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d9f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.TFRecordDataset(fp)\n",
    "# ds = ds.shuffle(buffer_size=min(1000, len(sequences))) # flaxmodels, https://zhuanlan.zhihu.com/p/552951305\n",
    "ds = ds.map(_parse_function, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed07e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, example in enumerate(ds):\n",
    "    if i == 3: break\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b7b6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_accumulation_steps = 16\n",
    "# train_mbs_per_replica = 2 # train_micro_batch_size_per_gpu in deepspeed\n",
    "tpu_size = 8  # jax.num_devices()\n",
    "cores_per_replica = 4  # mp=8, dp=8/4=2\n",
    "per_replica_batch = 1  # train_mbs_per_replica in run_clm_mp_xd.py, train_micro_batch_size_per_gpu in deepspeed\n",
    "train_batch_size = (gradient_accumulation_steps, per_replica_batch * tpu_size // cores_per_replica)\n",
    "max_len = 80  # max(len(s) for s in sequences) == 78\n",
    "# ds = ds.apply(tf.data.experimental.dense_to_ragged_batch(np.prod(self.bs), drop_remainder=True)) # mtj\n",
    "ds = ds.padded_batch(batch_size=np.prod(train_batch_size), padded_shapes={'input_ids': [max_len]},\n",
    "                     padding_values={'input_ids': 0}, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff03981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in ds: print(batch); break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc8895",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.prefetch(10)  # mesh-transformer-jax\n",
    "# ds = ds.repeat()  # gpt-neo/inputs.py\n",
    "# map shard directly over ds won't work, getting AttributeError: 'Tensor' object has no attribute 'numpy'\n",
    "# because inside tf.function?, see e.g.:\n",
    "# 1) https://stackoverflow.com/questions/34097281/convert-a-tensor-to-numpy-array-in-tensorflow\n",
    "# 2) https://github.com/tensorflow/tensorflow/issues/27519\n",
    "# ds = ds.map(partial(shard, batch_size=train_batch_size), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# matthias-wright/flaxmodels/training/stylegan2/data_pipeline.py\n",
    "ds_iter = iter(ds)\n",
    "ds_iter = map(lambda x: shard(x, batch_size=train_batch_size), ds_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffdb061",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in ds_iter: print(batch); break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cf7d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['input_ids'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
